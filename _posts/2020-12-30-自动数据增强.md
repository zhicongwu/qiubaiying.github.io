---
layout:     post
title:      自动数据增强
subtitle:   Learning Augmentation Strategies from Data 论文阅读
date:       2020-12-30
author:     ZC
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:
    - Data Augmentation
    - 论文阅读
---


## 1. Introduction

不同的数据集，由于其数据特征的不同，增强操作的选择也不同，因此手动数据增强需要对数据集有很专业的认识，而且很多时候增强操作和参数的选择只能依靠Trial and error来实现，因而手动增强需要耗费很大的人力物力。自动数据增强首次提出通过深度学习，在数据集上自动搜索数据增强操作的方法，论文证明其效果比手动数据增强的效果要好。而且其证明搜索出来的增强策略可以迁移，也就是在一个数据集上搜索出增强策略，然后在其它数据集上使用（这点表示存疑，相同类型的数据集可能效果还行，但是不同类型的数据集，可能反倒会产生反效果。）



## 2. Method
### 2.1 Search Space

每个搜索policy有五个subpolicy，每个subpolicy包含2个operatioans，每个operation有两个参数，分别是probability和magnitude。probability表示对一张图片应用此操作变换的概率，magnitude是指此操作的强度，比如旋转操作的角度。probability是一个离散值，从0到划分为11个离散值，magnitude划分为10个离散值。

具体操作是对每张图片从policy中随机选取一个subpolicy应用，即在每张图片上连续应用两个operations。因此一张图片有四种可能输出。
![](https://i.loli.net/2020/12/30/Y3c2sKdkreJPqQm.png)

### 2.2 Search Algorithm

论文中采用的是reinforcement learning算法。如图所示：

![](https://i.loli.net/2020/12/31/P7unIxQUDKJErGT.png)

controller从search space中采样出一个policy，将这个policy应用到数据集上，将augmented dataset放进child network进行训练，得到的accuracy作为reward signal传进controller，以此影响下一次的policy采样。论文中采用了15,000个child network，也就是说controller每次采样15,000个policy。之所以能够一次采样那么多policy，是为了提高搜索速度，而每个policy应用的数据集其实不是全部的数据集，只是一小部分而已。

## 3. Experimental setup

### 3.1 Baseline/Augmentation

参照组也会需要进行一些数据操作：standardizing the data, using horizontal flips with 50% probability, zero-padding and random crops, and finally Cutout with 16x16 pixels

数据增强： on one image, we first apply the baseline augmentation provided by the existing baseline methods, then apply the AutoAugment policy, then apply Cutout.

这里有些歧义，在数据增强组，先是进行baseline augmentation，但是这里的baseline augmentation是否有包括Cutout呢？（我认为是没有的）
所以数据增强组：standardizing the data, using horizontal flips with 50% probability, zero-padding and random crops，然后应用AotuAugment Policy，最后Cutout。

### 3.2 Dataset

**CIFAR10 CIFAR100 以及 SVHN**

## 4 Results

![](https://i.loli.net/2020/12/31/Q3zZbL6RFPHvAma.png)

## 5 Discussion

此论文通过深度学习来搜索增强策略，比传统的手动增强效果好。但是需要耗费大量的GPU时间，在实际应用中是不可取的。后续有很多论文都是在此论文的基础上进行改进的。问题主要在于搜索空间太大。

